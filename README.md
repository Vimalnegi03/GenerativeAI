# GenerativeAI Experiments

A modular and extensible playground for experimenting with various Generative AI strategies including chain-of-thought reasoning, custom tokenization, embeddings, memory-augmented retrieval (RAG), and multi-provider LLM integration.

## ğŸ“ Project Structure

```
GenerativeAI/
â”œâ”€â”€ chainOfThoughts*.py # CoT prompts (manual & auto, OpenAI & Gemini)
â”œâ”€â”€ few_shots*.py # Few-shot examples
â”œâ”€â”€ zero_shot_prompting*.py # Zero-shot examples
â”œâ”€â”€ personaBasedPrompting*.py # Persona-based prompting
â”œâ”€â”€ role_playing*.py # Role-playing prompt agents
â”œâ”€â”€ embeddings.py # Embedding generation utility
â”œâ”€â”€ memory_rag.py # Memory-augmented RAG
â”œâ”€â”€ recirpocate_rank_fusion_in_rag.py # RRF scoring for RAG
â”œâ”€â”€ tokenizer*.py # Tokenizer setup (HuggingFace)
â”œâ”€â”€ ollama_api.py # Ollama integration
â”œâ”€â”€ weather_agent*.py # Sample agent for weather queries
â”œâ”€â”€ read*.py # Sample agent used to basically generate markdown of code explanation of each line
â”œâ”€â”€ sql*.py # Sample agent used to basically used to interact with database using NLP
â”œâ”€â”€ webscrapper*.py #used to scrap chai_code_docs and generate output used query_routing in this
â”œâ”€â”€ docker-compose.*.yml # Docker configs
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ *.ipynb # Tokenizer experiments
â”œâ”€â”€ *.pdf # Reference docs

```
## ğŸš€ Features

âœ… Chain-of-Thought reasoning with OpenAI & Gemini  
âœ… Few-shot and zero-shot prompt engineering  
âœ… Persona-based and role-playing bots  
âœ… Custom tokenizer using HuggingFace  
âœ… Retrieval-Augmented Generation (RAG) pipelines  
âœ… Reciprocal Rank Fusion scoring for better document retrieval  
âœ… Dockerized microservice-ready setup  
âœ… Integration with Gemini, OpenAI, Ollama APIs  
âœ… Real-world agent demo: Weather Bot,Sql query writer,Mini Cursor,Read me generator
âœ… Web Scrapping with Multi query routing
âœ… Avanced Rags with query translation  

---

## ğŸŒ APIs Integrated
OpenAI GPT-3.5 / GPT-4

Gemini Pro

HuggingFace Transformers

Ollama (local LLM APIs)

## ğŸ§¾ Requirements
All dependencies are listed in requirements.txt. Major libraries:

openai

google-generativeai

langchain

huggingface_hub

transformers

faiss-cpu / chromadb

## ğŸš€ How to Run

1. **Clone the repo:**
   ```bash
   git clone https://github.com/Vimalnegi03/GenerativeAI/
   cd GenerativeAI
   ```

2. **Set up environment:**
   Install dependencies via pip or poetry:
   ```bash
   pip install -r requirements.txt
   ```

3. **Run Docker services (optional):**
   ```bash
   docker-compose up -d
   ```

4. **Experiment with scripts or notebooks:**
   - Launch Jupyter: `jupyter notebook`
   - Or run any `.py` script directly with proper API keys configured.

## ğŸ“Š Example Use Cases
ğŸ” Chain-of-Thought Prompting
```
python chainOfThoughtsAuto.openAI.py

```
ğŸ§  Retrieval-Augmented Generation

```
python memory_rag.py

```
ğŸ­ Persona Prompting (Gemini)
```
python personaBasedPrompting.gemini.py

```
## ğŸ§ª Notebooks

Tokenizer.huggingface.ipynb: Tokenizer setup using pretrained models

own_Tokenizer.huggingFace.ipynb: Custom tokenizer for domain-specific vocab

# ğŸ“Œ Notes
API keys must be stored as environment variables:

OPENAI_API_KEY

GOOGLE_GEMINI_API_KEY

Docker setup supports additional services like vector DB and graph DB.

## ğŸ“„ License

MIT License (or specify if different)

## âœï¸ Author

- Vimal Negi
- Contact: [vimalnegi2003@gmail.com]
