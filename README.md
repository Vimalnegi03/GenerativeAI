# GenerativeAI Experiments

A modular and extensible playground for experimenting with various Generative AI strategies including chain-of-thought reasoning, custom tokenization, embeddings, memory-augmented retrieval (RAG), and multi-provider LLM integration.

## ğŸ“ Project Structure

```
GenerativeAI/
â”‚
â”œâ”€â”€ chainOfThoughtsAuto.gemini.py         # Automatic CoT with Gemini
â”œâ”€â”€ chainOfThoughtsAuto.openAI.py         # Automatic CoT with OpenAI
â”œâ”€â”€ chainOfThoughtsmanual.gemini.py       # Manual CoT with Gemini
â”œâ”€â”€ chainOfThoughtsmanual.openAI.py       # Manual CoT with OpenAI
â”‚
â”œâ”€â”€ few_shots.gemini.py                   # Few-shot prompting with Gemini
â”œâ”€â”€ few_shots.openAI.py                   # Few-shot prompting with OpenAI
â”‚
â”œâ”€â”€ tokenizer.huggingface.ipynb           # Tokenizer setup using HuggingFace
â”œâ”€â”€ own_Tokenizer.huggingFace.ipynb       # Custom tokenizer example
â”‚
â”œâ”€â”€ embeddings.py                         # Embedding generation utilities
â”œâ”€â”€ memory_rag.py                         # RAG (Retrieval Augmented Generation)
â”‚
â”œâ”€â”€ ollama_api.py                         # Integration with Ollama API
â”œâ”€â”€ cursor.auto.gemini.py                 # Gemini integration (possibly cursor-like)
â”‚
â”œâ”€â”€ docker-compose.yaml                   # Base Compose setup
â”œâ”€â”€ docker-compose.db.yml                 # DB-specific services
â”œâ”€â”€ docker-compose.graph.yml              # Graph DB services
â”‚
â”œâ”€â”€ Node.pdf                              # Possibly documentation or architecture
â”œâ”€â”€ check.py                              # Utility script
â”œâ”€â”€ .gitignore
```

## ğŸ”§ Requirements

- Python 3.8+
- Jupyter (for notebooks)
- Docker & Docker Compose
- LLM API access (e.g., OpenAI, Gemini, Ollama)

## ğŸš€ How to Run

1. **Clone the repo:**
   ```bash
   git clone https://github.com/Vimalnegi03/GenerativeAI/
   cd GenerativeAI
   ```

2. **Set up environment:**
   Install dependencies via pip or poetry:
   ```bash
   pip install -r requirements.txt
   ```

3. **Run Docker services (optional):**
   ```bash
   docker-compose up -d
   ```

4. **Experiment with scripts or notebooks:**
   - Launch Jupyter: `jupyter notebook`
   - Or run any `.py` script directly with proper API keys configured.

## ğŸ§  Key Features

- âœ… Chain-of-Thought prompting (manual & automated)
- âœ… Few-shot learning with prompt templates
- âœ… HuggingFace tokenizer training
- âœ… Embedding generation
- âœ… Retrieval-Augmented Generation (RAG)
- âœ… Docker-based backend (DB/Graph support)
- âœ… Multi-provider LLM integration (OpenAI, Gemini, Ollama)

## ğŸ“„ License

MIT License (or specify if different)

## âœï¸ Author

- Vimal Negi
- Contact: [vimalnegi2003@gmail.com]
